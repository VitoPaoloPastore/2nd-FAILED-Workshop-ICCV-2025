---
title: Home
nav: false
---
{% include figure.html img="LOGO failed second.svg" alt="logo" width="80%" %}

<div style="text-align: justify">

Welcome to the forefront of ethical AI innovation! 

In recent decades, Artificial Intelligence (AI) has experienced an unprecedented surge, marked by the development of intricate machine learning models boasting vast parameter counts. Yet, alongside this growth looms a critical concern: the presence of biases within these models, perpetuating disparities and ethical dilemmas. The scientific community has increasingly turned its focus towards understanding and addressing model bias, as evidenced by a significant uptick in research across various disciplines. This surge coincides with the impending European Union's AI Act, emphasizing <i>ethics, transparency, and accountability</i> in AI systems. 

In response to these pressing challenges, we present the second edition of the workshop "FAILED: Fairness and Ethics in AI: Facing the Challenge through Model Debiasing". This initiative aims to convene experts and practitioners from diverse backgrounds to explore innovative strategies for rectifying biases and promoting fairness and transparency in AI systems, particularly in the domain of Computer Vision. By fostering interdisciplinary discussions and sharing cutting-edge solutions, FAILED seeks to propel advancements in building unbiased and fair AI models. Join us in this collaborative endeavor to shape a future where AI serves as a force for equity and inclusivity. Together, let's pave the way towards a more ethical and fair AI landscape. 

Join us at FAILED, a satellite workshop of ICCV 2025, and be a part of this transformative journey.
    
</div>
